# Kaggle-Titanic
Attempt on the Titanic dataset from Kaggle


Some of the models that I will be attempting to use are:

1) Logistic Regression
2) Decision Trees
3) Random Forest
4) Gradient Boosting
5) XGBoost
6) To be further extended with more knowledge.

Attempts:

1) Attempt 1 on 4th October 2020:
Columns used: Age, Sex, Scaled Fare, Dummy variables: EmbarkedC, EmbarkedS, Pclass_Upper, Pclass_Middle
Accuracy on test set: 0.76794

Comments:
In attempt 2, will proceed to include all dummy(EmbarkedQ,Pclass_Lower, Male,Female) and unscaled fare



Overall reflections and evaluations:

