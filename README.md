# Kaggle-Titanic
Attempt on the Titanic dataset from Kaggle


Some of the models that I will be attempting to use are:

1) Logistic Regression
2) Decision Trees
3) Random Forest
4) Gradient Boosting
5) XGBoost
6) To be further extended with more knowledge.

Attempts:

1) Attempt 1.1 on 4th October 2020:
Columns used: Age, Sex, Scaled Fare, Dummy variables: EmbarkedC, EmbarkedS, Pclass_Upper, Pclass_Middle
Accuracy on test set: 0.76794

2) Attempt 1.2 on 5th October 2020:
Columns used: Sex, Age,	SibSp, Fare, EmbarkedS, Pclass_Middle, Pclass_Lower
Accuracy on test set:


Overall reflections and evaluations:

